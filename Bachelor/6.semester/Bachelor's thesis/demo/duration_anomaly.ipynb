{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "committed-tournament",
   "metadata": {},
   "source": [
    "This notebook demonstrates in detail how dows the anomaly detection in request durations work.  \n",
    "What is the process?  \n",
    " 1) Data in RQA have generally form of normal, F or triangular distribution -> we generate some mock data and explain why  \n",
    "    These data mocks the raw reference dataset which must first be cleaned for it to be used as detection arbiter.\n",
    " 2) Outliers are detected using combination of DBSCAN algorithm and Modified Z-Score method.\n",
    " 3) Anomaly is found among the detected outliers using HDBSCAN or DBSCAN and Modified Z-Score.\n",
    " 4) Valid data are kept as reference data for further detections.  \n",
    "    (step 3 can be skipped in praxis as it has no effect in cleaning the data, here it's performed for demonstration purposes)\n",
    " 5) We generate the same data again but in smaller number and use the reference data to perform the anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r \"nuget:YSoft.Rqa.AnomalyDetection.Application\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "using YSoft.Rqa.AnomalyDetection.Application;\n",
    "using YSoft.Rqa.AnomalyDetection.Application.Model;\n",
    "using YSoft.Rqa.AnomalyDetection.Application.Services;\n",
    "using YSoft.Rqa.AnomalyDetection.Data.Model.Csv;\n",
    "using YSoft.Rqa.AnomalyDetection.Data.Model.Graylog;\n",
    "using MoreLinq;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "var generator = new TrafficGenerator();\n",
    "var detector = new DurationAnomalyDetector(new Clusterer());\n",
    "var plotter = new Plotter();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-childhood",
   "metadata": {},
   "source": [
    "Let's choose a distribution for the rest of the demo. (uncomment the desired one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "//var distributionType = \"normal\";\n",
    "var distributionType = \"F\";\n",
    "//var distributionType = \"triangular\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-colonial",
   "metadata": {},
   "source": [
    "Let's see how the typical RQA data look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "var count = 5000;\n",
    "var timeSpan = new DateTimeInterval(DateTime.Now.AddDays(-7), DateTime.Now);\n",
    "var timestamps = generator.GenerateRequestTimestamps(count, timeSpan);\n",
    "List<double> durations;\n",
    "if (distributionType == \"normal\")\n",
    "    durations = ProbabilityDistribution.Normal(count, mean: 260, sigma: 30).Data;\n",
    "else if(distributionType == \"F\")\n",
    "    durations = ProbabilityDistribution.FDistribution(count, center: 150, dfNum: 30, dfDen: 60).Data;\n",
    "else\n",
    "    durations = ProbabilityDistribution.Triangular(count, start: 80, end: 420, peak: 150).Data;\n",
    "\n",
    "var requests = Enumerable.Range(0, count).Select(i => new RequestDataPoint { Timestamp = timestamps[i], Duration = durations[i]});\n",
    "var rg = new RequestGroup(\"MockService\", \"MockRequestType\", requests.ToList());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plotter.Histogram(rg.ValidData, title: \"Basic distribution\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-prevention",
   "metadata": {},
   "source": [
    "Let's add some random outliers to the data. 2% of the valid data in wider range around the distribution seems about right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "var interval = distributionType == \"normal\" ? new Interval(100, 420) : distributionType == \"F\" ? new Interval(0, 500) : new Interval(0, 600);\n",
    "durations.AddRange(ProbabilityDistribution.Uniform((int)(durations.Count*0.02), interval));\n",
    "timestamps.AddRange(generator.GenerateRequestTimestamps((int)(durations.Count*0.02), timeSpan));\n",
    "\n",
    "requests = Enumerable.Range(0, durations.Count).Select(i => new RequestDataPoint { Timestamp = timestamps[i], Duration = durations[i]});\n",
    "rg = new RequestGroup(\"MockService\", \"MockRequestType\", requests.ToList());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plotter.Histogram(rg.ValidData, title: \"Mock data with random outliers\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-factor",
   "metadata": {},
   "source": [
    "Finally add an anomaly. Anomaly is an repetitive occurence of certain outliers (= cluster of outliers) outside the valid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = distributionType == \"normal\" ? new Interval(380, 400) : distributionType == \"F\" ? new Interval(350, 370) : new Interval(450, 470);\n",
    "durations.AddRange(ProbabilityDistribution.Uniform((int)(durations.Count*0.06), interval));\n",
    "timestamps.AddRange(generator.GenerateRequestTimestamps((int)(durations.Count*0.06), timeSpan));\n",
    "\n",
    "requests = Enumerable.Range(0, durations.Count).Select(i => new RequestDataPoint { Timestamp = timestamps[i], Duration = durations[i]});\n",
    "rg = new RequestGroup(\"MockService\", \"MockRequestType\", requests.ToList());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plotter.Histogram(rg.ValidData, title: \"Raw reference data with an anomaly\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-balloon",
   "metadata": {},
   "source": [
    "Outlier detection - DBSCAN + Modified Z-Score  \n",
    "1) DBSCAN: to find the center of the dataset (= the biggest cluster) from which we obtain the parameters for Modified Z-Score.  \n",
    "2) Modified Z-Score: used for the detection itself.  \n",
    "\n",
    "Why in this way?  \n",
    " * DBSCAN alone might:\n",
    "   * Not find anything in adverse dataset.\n",
    "   * Not cover the whole cluster (instead of one big it might find several smaller ones / just the very dense center of the cluster == too strict on outliers).\n",
    "   * Cover more than it should (include some noise datapoints around itself).\n",
    " * Modified Z-Score alone might:\n",
    "   * Have median and standard deviation impacted by big anomaly or multiple ones. Simply put, it would shift the valid area towards the anomaly -> part of the anomaly would have been proclaimed as valid and some lower valid data would have become outliers.  \n",
    "   \n",
    "The reason for this is simple. The detection is made for general purpose. The input data are unknown (each request of every service looks a bit different) so it cannot be optimized or even trained on a specific dataset. That's why the DBSCAN returns only \"rough\" result which is than corrected with the Modified Z-Score method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.FindOutliers(rg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plotter.Scatter(rg.OutlierDetectionClusters, \"Clusters found by DBSCAN\"));\n",
    "display(plotter.DetectionScatter(rg, \"Final outlier detection after applying Modified Z-Score\"));\n",
    "display(plotter.DetectionHistogram(rg));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-product",
   "metadata": {},
   "source": [
    "Anomaly detection - (H)DBSCAN + Modified Z-Score  \n",
    "1) Find clusters in outliers using HDBSCAN for large datasets, DBSCAN for small ones.\n",
    "2) Close clusters are merged for the reasons of \"rough\" clustering due to general purpose explained above.\n",
    "3) Modified Z-Score smooths the clusters.\n",
    "4) If a cluster is big enough (default is >= 5% of the whole dataset), it is an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.FindAnomalies(rg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plotter.Scatter(rg.AnomalyDetectionClusters, \"Clusters found by (H)DBSCAN\"));\n",
    "display(plotter.Scatter(rg.AnomalyDetectionMergedClusters, \"Clusters after merging the close ones\"));\n",
    "display(plotter.DetectionScatter(rg, \"Final anomaly detection\"));\n",
    "display(plotter.DetectionHistogram(rg));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-germany",
   "metadata": {},
   "source": [
    "Now that we identified valid data, let's use it for further detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "var referenceData = rg.ValidData.Clone();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-platform",
   "metadata": {},
   "source": [
    "Let's generate new data. Should we consider a 1 week reference window and performing detection 2x a day, it makes approximately 7.15% of the reference dataset per detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "var newDataCount = (int)(count * 0.0715);\n",
    "List<double> newData;\n",
    "Interval outlierInterval;\n",
    "Interval anomalyInterval;\n",
    "// valid data\n",
    "if (distributionType == \"normal\"){\n",
    "    newData = ProbabilityDistribution.Normal(newDataCount, mean: 260, sigma: 30).Data;\n",
    "    outlierInterval = new Interval(100, 420);\n",
    "    anomalyInterval = new Interval(380, 400);\n",
    "}\n",
    "else if(distributionType == \"F\"){\n",
    "    newData = ProbabilityDistribution.FDistribution(newDataCount, center: 150, dfNum: 75, dfDen: 40).Data;\n",
    "    outlierInterval = new Interval(0, 500);\n",
    "    anomalyInterval = new Interval(350, 370);\n",
    "}\n",
    "else{\n",
    "    newData = ProbabilityDistribution.Triangular(newDataCount, start: 80, end: 420, peak: 150).Data;\n",
    "    outlierInterval = new Interval(0, 600);\n",
    "    anomalyInterval = new Interval(460, 480);\n",
    "}\n",
    "// outliers and an anomaly\n",
    "newData.AddRange(ProbabilityDistribution.Uniform((int)(Math.Max(5, newData.Count*0.02)), outlierInterval));\n",
    "newData.AddRange(ProbabilityDistribution.Uniform((int)(Math.Max(5, newData.Count*0.06)), anomalyInterval));\n",
    "newData = newData.Shuffle().ToList();\n",
    "\n",
    "var newDataTimestamps = generator.GenerateRequestTimestamps((int)(newData.Count), new DateTimeInterval(DateTime.Now.AddDays(-0.5), DateTime.Now));\n",
    "requests = Enumerable.Range(0, newData.Count).Select(i => new RequestDataPoint { Timestamp = newDataTimestamps[i], Duration = newData[i]});\n",
    "rg = new RequestGroup(\"MockService\", \"MockRequestType\", requests.ToList());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plotter.Scatter(rg.ValidData, title: \"New data in which to find an anomaly\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-mistress",
   "metadata": {},
   "source": [
    "Owing to the reference data, there is no longer need to use the DBSCAN. We already know how the data should look like.  \n",
    "The Modified Z-Score parameters (median and MAD) are obtained from the reference dataset and applied on the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.FindOutliers(rg, referenceData);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plotter.DetectionScatter(rg, \"Outlier detection with reference dataset\"));\n",
    "display(plotter.DetectionHistogram(rg));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-columbia",
   "metadata": {},
   "source": [
    "Anomaly detection (=clustering of outliers) isn't directly incluenced by the reference dataset. However, it still refers to the valid data in cases of determining neighbors or extreme values of distances. These computations are therefore made more precise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.FindAnomalies(rg, referenceData);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plotter.Scatter(rg.AnomalyDetectionClusters, \"Clusters found by (H)DBSCAN\"));\n",
    "display(plotter.Scatter(rg.AnomalyDetectionMergedClusters, \"Clusters after merging the close ones\"));\n",
    "\n",
    "display(plotter.DetectionScatter(rg, \"Final anomaly detection\"));\n",
    "display(plotter.DetectionHistogram(rg));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-diamond",
   "metadata": {},
   "source": [
    "Sometimes, what might look like an anomaly is not desired to be. For instance, valid data are in range of 40-60 and than \"anomalous\" in range 90-100. There's a clear gap and sufficient amount of outliers for an anomaly. Still, one can argue that 30ms is next to nothing. For this purpose, FindAnomalies methods provides a \"tolerance\" paramater specifying an \"anomaly-free zone\" around the valid data in which nothing is an anomaly.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-string",
   "metadata": {},
   "source": [
    "Let's demonstrate it on our example. With a sufficient tolerance there should be no anomalies detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = new RequestGroup(\"MockService\", \"MockRequestType\", requests.ToList());\n",
    "detector.FindOutliers(rg, referenceData);\n",
    "detector.FindAnomalies(rg, referenceData, tolerance: 150);\n",
    "rg.Anomalies.Length()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
